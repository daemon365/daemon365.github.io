<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=generator content="Hugo 0.128.1"><link rel="shortcut icon" href=/imgs/icons/favicon.ico><title>kubernetes CNI(Container Network Inferface) - Daemon</title>
<meta name=author content="daemon365"><meta name=description content="Don't let yourself stop."><meta name=keywords content="cni,kubernetes,network"><meta property="og:title" content="kubernetes CNI(Container Network Inferface)"><meta name=twitter:title content="kubernetes CNI(Container Network Inferface)"><meta property="og:type" content="article"><meta property="og:url" content="https://daemon365.dev/2024/04/20/kubernetes-cnicontainer-network-inferface/"><meta property="og:description" content="为什么需要 CNI 在 kubernetes 中，pod 的网络是使用 network namespace 隔离的，但是我们有时又需要互相访问网络，这就需要一个网络插件来实现 pod 之间的网络通信。CNI 就是为了解决这个问题而诞生的。CNI 是 container network interface 的缩写，它是一个规范，定"><meta name=twitter:description content="为什么需要 CNI 在 kubernetes 中，pod 的网络是使用 network namespace 隔离的，但是我们有时又需要互相访问网络，这就需要一个网络插件来实现 pod 之间的网络通信。CNI 就是为了解决这个问题而诞生的。CNI 是 container network interface 的缩写，它是一个规范，定"><meta property="og:image" content="https://daemon365.dev/imgs/icons/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://daemon365.dev/imgs/icons/favicon.ico"><meta property="article:published_time" content="2024-04-20T00:00:00+08:00"><meta property="article:modified_time" content="2024-04-20T00:00:00+08:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://daemon365.dev/assets/css/fuji.min.4e0456c767a797dadceacfba968921e887d900af9fd8d0953bebc1524ea1dec6c6a4a5ec0c0b77280884a642028ce374f31206dd96c6d7d143d5ee3c372f2c31.css integrity="sha512-TgRWx2enl9rc6s+6lokh6IfZAK+f2NCVO+vBUk6h3sbGpKXsDAt3KAiEpkICjON08xIG3ZbG19FD1e48Ny8sMQ=="></head><body data-theme=light data-theme-auto=false><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://daemon365.dev/>Daemon</a>
<span class=title-sub>Don't let yourself stop.</span></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://daemon365.dev/2024/04/20/kubernetes-cnicontainer-network-inferface/>kubernetes CNI(Container Network Inferface)</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2024-04-20</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;2368 words</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/cni>cni</a>&nbsp;<a href=/tags/kubernetes>kubernetes</a>&nbsp;<a href=/tags/network>network</a>&nbsp;</span></div><div class="post-content markdown-body"><h2 id=为什么需要-cni>为什么需要 CNI</h2><p>在 kubernetes 中，pod 的网络是使用 network namespace 隔离的，但是我们有时又需要互相访问网络，这就需要一个网络插件来实现 pod 之间的网络通信。CNI 就是为了解决这个问题而诞生的。CNI 是 container network interface 的缩写，它是一个规范，定义了容器运行时如何配置网络。CNI 插件是实现了 CNI 规范的二进制文件，它可以被容器运行时调用，来配置容器的网络。</p><h2 id=docker-网络>Docker 网络</h2><h3 id=基础>基础</h3><p>计算机五层网络如下：</p><p><img class=img-zoomable src=/images/4bcdd10b-42da-470b-91b0-d87746410aeb.png alt></p><p>如果我们想把 pod 中的网络对外，首先想到的就是七层代理，比如nginx，但是我们并不知道 pod 里的网络一定是 http，甚至他可能不是tcp。所以我们像做一些网络操作，就不能在五层做了，只能在二三四层做。</p><h3 id=docker-实验>Docker 实验</h3><p>当我们在物理机上启动 docker daemon 不需要启动任何容器的时候，使用 ip a 命令查看网卡，发现多了一个 docker0</p><pre><code class=language-bash>4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:9b:65:e1:01 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
</code></pre><p>docker0 是一个 linux Bridge 设备，这个可以理解成一个虚拟的交换机，用来做二层网络的转发。当我们启动一个容器的时候，docker 会为这个容器创建一个 veth pair 设备，一个端口挂载在容器的 network namespace 中，另一个端口挂载在 docker0 上。这样容器就可以和 docker0 上的其他容器通信了。</p><pre><code class=language-bash>docker run -d --rm -it ubuntu:22.04 sleep 3000
</code></pre><p>在物理机上查看 ip a</p><pre><code class=language-bash>8: veth6bc75d9@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default
    link/ether d6:87:ca:5c:54:51 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::d487:caff:fe5c:5451/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>docker 容器里面 ip a</p><pre><code class=language-bash>7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre><p>再启动一个 docker</p><pre><code class=language-bash>docker run --name test -d --rm -it ubuntu:22.04 sleep 3000
# ip a
9: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre><p>这样两个容器就可以通过 docker0 通信了。</p><pre><code class=language-bash>root@b19a3dc4b32d:/# ping  172.17.0.2
PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.
64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.055 ms
</code></pre><h3 id=通信方式>通信方式</h3><p><img class=img-zoomable src=/images/a6754f75-f177-42d3-b9d3-0d362ef038a9.png alt></p><h2 id=cni-网络>CNI 网络</h2><p>当两个 pod 在同一 node 上的时候，我们可以使用像上述 docker 的 bridge 的方式通信是没问题的。但是 kubernetes 是这个多节点的集群，当 pod 在不同的 node 上的时候，直接通信肯定不行了，这时候我们需要一些办法来解决这个问题。</p><h3 id=udp-封包>UDP 封包</h3><p>当 pod 在不同节点上的时候，两个 pod 不可以直接通信，那最简单的方式就是通过 udp 封包，把整个网络包使用 udp 封包起来，然后第二个节点再解包，然后发给网桥。</p><p><img class=img-zoomable src=/images/2fca7256-2cac-436f-a379-4e12891fac39.png alt></p><p>整个过程就是 node1 上的 pod 把网络包封装，然后由于 <code>process</code> 再封装发给 node2，node2 再解包，然后发给 pod2。</p><p>process 是 cni 实现的进程，很多 cni 都实现 udp 封包的方式，比如 flannel,cailco 等。</p><p>至于我们怎么知道目标 ip （pod 的 ip） 是在哪台主机上，这个就有很多中方式了，比如把每台机器发配 ip 分配不同的网段，甚至于把这些对应关系写到 etcd 中。</p><h3 id=vxlan>VXLAN</h3><p>上述的 udp 封包方式，是可以满足基本需求但是。cni 创建的 process 进程是一个用户态的进程，每个包要在 node1 上从内核态 copy 到用户态，然后再封包，再 copy 到内核态，再发给 node2，再从内核态 copy 到用户态，再解包，再 copy 到内核态，再发给 pod2。这样的方式效率很低。所以我们使用一种更加高效的方式，就是 vxlan。</p><p><strong>VXLAN 是什么?</strong></p><p>VXLAN（Virtual Extensible LAN）是一种网络虚拟化技术，用于解决大规模云计算环境中的网络隔离、扩展性和灵活性问题。VXLAN 允许网络工程师在现有的网络架构上创建一个逻辑网络层，这可以使得数据中心的网络设计变得更加灵活和可扩展。</p><p><strong>为什么性能会高？</strong></p><p>VXLAN 是在内核态实现的，原理和 udp 封包一样，只不过是在内核态实现的，数据包不会在内核态和用户态之间 copy，所以效率会高很多。</p><h3 id=ip-路由>ip 路由</h3><p>就算是 vxlan，也是需要封包和解包的，这样的方式效率还是不够高，所以我们可以使用 ip 路由的方式。</p><p>ip 路由故名思意，就是使用路由表来实现 pod 之间的通信。这样的方式效率最高，但是配置比较复杂，需要配置路由表。</p><p>而且路由表跳转是二层网络实现的，所以又要要求所有 node 在同一个二层网络中。</p><p><img class=img-zoomable src=/images/7be8c8c9-a60b-4717-9f5a-a3e6f44ebed9.png alt></p><p>查看 node1 上的 container 的是设备</p><pre><code class=language-BASH>ip a
2: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 66:5e:d8:8d:86:ba brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.10.184.69/32 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::645e:d8ff:fe8d:86ba/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>这个和主机上是对应的是一个 veth pair 设备，一个端口挂载在容器的 network namespace 中，一边挂载在主机上。</p><pre><code class=language-bash># 主机
ip a
10: calia78b8700057@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-0da431c8-dd8b-ca68-55e6-40b04acf78d6
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>当 pod 中的数据包来到主机 查看 node1 上的路由表 会命中一下这条路由 这条的意思是跳到<code>192.168.229.102</code>节点使用 ens33 设备</p><pre><code class=language-bash>ip r
172.10.190.0/26 via 192.168.229.102 dev ens33 proto bird
</code></pre><p>当 数据包来到 node2 上的时候 我们看下 node2 的路由表</p><pre><code class=language-BASH>ip r
172.10.190.2 dev calie28ee63d6b0 scope link
ip a
7: calie28ee63d6b0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netns cni-dd892c92-1826-f648-2b8c-d22618311ca9
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>这个设备是 veth pair 设备，对应的容器内的</p><pre><code class=language-BASH>ip a
2: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether fa:a6:2f:97:58:28 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.10.190.2/32 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f8a6:2fff:fe97:5828/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>这样node2上的 172.10.190.2 pod 就可以收到数据包了。</p><h4 id=路由跳转>路由跳转</h4><p>路由跳转是怎么实现的？</p><p>路由跳转是通过路由表来实现的，它作用在二层上，所以当跳转的时候，直接修改数据包的目标 mac 地址（如果知道的话是使用 ARP 协议获得）。</p><p>所以当我们访问百度的时候，获得百度的ip的时候，数据包会经过很多路由器，每个路由器都会修改数据包的目标 mac 地址，这样数据包就可以到达百度的服务器了。</p><h4 id=felix>Felix</h4><p>那么主机上的路由表是怎么来的呢？</p><p>这个就是 cni 的实现了，cni 会调用 felix 这个进程，felix 会根据 cni 的配置来配置路由表。</p><h4 id=bgp>BGP</h4><p>那么 node1 怎么知道对应的 pod ip 在哪个 node 上呢？</p><p>这个就是 BGP 协议了，BGP 是一个路由协议，用来告诉 node1 对应的 pod ip 在哪个 node 上。</p><p>这个协议很重，之前都是用到互联网上，比如我们刚才距离的百度的时候，经过那么多路由器，每个路由器怎么知道要跳到哪，他们之间就是通过 BGP 协议来告诉对方自己的路由表，再经过一系列的学习优化。</p><h3 id=ip-in-ip>ip in ip</h3><p>刚才也说过了，ip 路由是最高效的，是因为它作用在二层网络上，这就需要保证所有的 node 在同一个二层网络上。但是有时候我们的 node 不在同一个二层网络上，这时候我们可以使用 ip in ip。</p><p>简单来说就是如果 node 之间在一个二层网络上，那么就直接使用 ip 路由，如果不在，那么就使用 ip in ip，把数据包封装起来，然后再发给对应的 node。</p><p>ip-in-ip 是一种隧道技术，它将一个 IP 数据包封装在另一个 IP 数据包中，这样就可以在一个 IP 网络上传输另一个 IP 网络的数据包。</p><pre><code class=language-bash>172.10.180.0/24 via 192.168.228.28 tunl0
</code></pre><p><img class=img-zoomable src=/images/62ebd840-1785-46f6-bd04-7b4e78c8cc0b.png alt></p><p>这个只是在源数据包的三层上再封装一层，三层数据包和二层数据包。这样性能方面稍微比使用了 udp 的 vxlan 要好一点。但是最好还是避免使用ip in ip, 尽量保证 node 在同一个二层网络上。</p></div></article><div class="license markdown-body"><blockquote><p>Unless otherwise noted, the content of this site is licensed under <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a>.</p></blockquote></div><div class=post-comment data-comment=utterances><span class=post-comment-notloaded><i class="iconfont icon-chatbox-ellipses-sharp"></i>&nbsp;Load comments
</span><script>function loadComment(){var e,n=document.querySelector(".post-comment"),t=document.body.getAttribute("data-theme");t==="auto"?t=window.matchMedia("(prefers-color-scheme: dark)").matches?"photon-dark":"github-light":t=t==="dark"?"photon-dark":"github-light",e=document.createElement("script"),e.src="https://utteranc.es/client.js",e.setAttribute("repo","daemon365/daemon365.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),e.setAttribute("async",""),document.querySelector(".post-comment").appendChild(e),document.querySelector("span.post-comment-notloaded").setAttribute("style","display: none;")}</script></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archives</a></li><li><a href=/index.xml>RSS</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/daemon365 target=_blank><span>My GitHub</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bbr/>BBR</a>
</span><span><a href=/tags/boltdb/>Boltdb</a>
</span><span><a href=/tags/breaker/>Breaker</a>
</span><span><a href=/tags/cdi/>Cdi</a>
</span><span><a href=/tags/cgroup/>Cgroup</a>
</span><span><a href=/tags/client-go/>Client-Go</a>
</span><span><a href=/tags/cni/>Cni</a>
</span><span><a href=/tags/containerd/>Containerd</a>
</span><span><a href=/tags/containerd-shim/>Containerd-Shim</a>
</span><span><a href=/tags/cri/>Cri</a>
</span><span><a href=/tags/csi/>Csi</a>
</span><span><a href=/tags/docker/>Docker</a>
</span><span><a href=/tags/etcd/>Etcd</a>
</span><span><a href=/tags/gin/>Gin</a>
</span><span><a href=/tags/go/>Go</a>
</span><span><a href=/tags/golang/>Golang</a>
</span><span><a href=/tags/grpc/>Grpc</a>
</span><span><a href=/tags/iptables/>Iptables</a>
</span><span><a href=/tags/ipvs/>Ipvs</a>
</span><span><a href=/tags/istio/>Istio</a>
</span><span><a href=/tags/kratos/>Kratos</a>
</span><span><a href=/tags/kube-proxy/>Kube-Proxy</a>
</span><span><a href=/tags/kubelet/>Kubelet</a>
</span><span><a href=/tags/kubernetes/>Kubernetes</a>
</span><span><a href=/tags/linux/>Linux</a>
</span><span><a href=/tags/lua/>Lua</a>
</span><span><a href=/tags/makefile/>Makefile</a>
</span><span><a href=/tags/mysql/>Mysql</a>
</span><span><a href=/tags/namespace/>Namespace</a>
</span><span><a href=/tags/network/>Network</a>
</span><span><a href=/tags/nginx/>Nginx</a>
</span><span><a href=/tags/opentelemetry/>Opentelemetry</a>
</span><span><a href=/tags/prometheus/>Prometheus</a>
</span><span><a href=/tags/protobuf/>Protobuf</a>
</span><span><a href=/tags/rabbitmq/>RabbitMQ</a>
</span><span><a href=/tags/redis/>Redis</a>
</span><span><a href=/tags/runc/>Runc</a>
</span><span><a href=/tags/service-mesh/>Service Mesh</a>
</span><span><a href=/tags/sidecar/>Sidecar</a>
</span><span><a href=/tags/sqlx/>Sqlx</a>
</span><span><a href=/tags/thrift/>Thrift</a>
</span><span><a href=/tags/unionfs/>UnionFS</a>
</span><span><a href=/tags/viper/>Viper</a>
</span><span><a href=/tags/vscode/>Vscode</a>
</span><span><a href=/tags/wire/>Wire</a>
</span><span><a href=/tags/zap/>Zap</a>
</span><span><a href=/tags/%E4%BA%8B%E5%8A%A1/>事务</a>
</span><span><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a>
</span><span><a href=/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/>源码分析</a>
</span><span><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>设计模式</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#为什么需要-cni>为什么需要 CNI</a></li><li><a href=#docker-网络>Docker 网络</a><ul><li><a href=#基础>基础</a></li><li><a href=#docker-实验>Docker 实验</a></li><li><a href=#通信方式>通信方式</a></li></ul></li><li><a href=#cni-网络>CNI 网络</a><ul><li><a href=#udp-封包>UDP 封包</a></li><li><a href=#vxlan>VXLAN</a></li><li><a href=#ip-路由>ip 路由</a></li><li><a href=#ip-in-ip>ip in ip</a></li></ul></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archives</a></li><li><a href=/index.xml>RSS</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/daemon365 target=_blank><span>My GitHub</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bbr/>BBR</a>
</span><span><a href=/tags/boltdb/>Boltdb</a>
</span><span><a href=/tags/breaker/>Breaker</a>
</span><span><a href=/tags/cdi/>Cdi</a>
</span><span><a href=/tags/cgroup/>Cgroup</a>
</span><span><a href=/tags/client-go/>Client-Go</a>
</span><span><a href=/tags/cni/>Cni</a>
</span><span><a href=/tags/containerd/>Containerd</a>
</span><span><a href=/tags/containerd-shim/>Containerd-Shim</a>
</span><span><a href=/tags/cri/>Cri</a>
</span><span><a href=/tags/csi/>Csi</a>
</span><span><a href=/tags/docker/>Docker</a>
</span><span><a href=/tags/etcd/>Etcd</a>
</span><span><a href=/tags/gin/>Gin</a>
</span><span><a href=/tags/go/>Go</a>
</span><span><a href=/tags/golang/>Golang</a>
</span><span><a href=/tags/grpc/>Grpc</a>
</span><span><a href=/tags/iptables/>Iptables</a>
</span><span><a href=/tags/ipvs/>Ipvs</a>
</span><span><a href=/tags/istio/>Istio</a>
</span><span><a href=/tags/kratos/>Kratos</a>
</span><span><a href=/tags/kube-proxy/>Kube-Proxy</a>
</span><span><a href=/tags/kubelet/>Kubelet</a>
</span><span><a href=/tags/kubernetes/>Kubernetes</a>
</span><span><a href=/tags/linux/>Linux</a>
</span><span><a href=/tags/lua/>Lua</a>
</span><span><a href=/tags/makefile/>Makefile</a>
</span><span><a href=/tags/mysql/>Mysql</a>
</span><span><a href=/tags/namespace/>Namespace</a>
</span><span><a href=/tags/network/>Network</a>
</span><span><a href=/tags/nginx/>Nginx</a>
</span><span><a href=/tags/opentelemetry/>Opentelemetry</a>
</span><span><a href=/tags/prometheus/>Prometheus</a>
</span><span><a href=/tags/protobuf/>Protobuf</a>
</span><span><a href=/tags/rabbitmq/>RabbitMQ</a>
</span><span><a href=/tags/redis/>Redis</a>
</span><span><a href=/tags/runc/>Runc</a>
</span><span><a href=/tags/service-mesh/>Service Mesh</a>
</span><span><a href=/tags/sidecar/>Sidecar</a>
</span><span><a href=/tags/sqlx/>Sqlx</a>
</span><span><a href=/tags/thrift/>Thrift</a>
</span><span><a href=/tags/unionfs/>UnionFS</a>
</span><span><a href=/tags/viper/>Viper</a>
</span><span><a href=/tags/vscode/>Vscode</a>
</span><span><a href=/tags/wire/>Wire</a>
</span><span><a href=/tags/zap/>Zap</a>
</span><span><a href=/tags/%E4%BA%8B%E5%8A%A1/>事务</a>
</span><span><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a>
</span><span><a href=/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/>源码分析</a>
</span><span><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>设计模式</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#为什么需要-cni>为什么需要 CNI</a></li><li><a href=#docker-网络>Docker 网络</a><ul><li><a href=#基础>基础</a></li><li><a href=#docker-实验>Docker 实验</a></li><li><a href=#通信方式>通信方式</a></li></ul></li><li><a href=#cni-网络>CNI 网络</a><ul><li><a href=#udp-封包>UDP 封包</a></li><li><a href=#vxlan>VXLAN</a></li><li><a href=#ip-路由>ip 路由</a></li><li><a href=#ip-in-ip>ip in ip</a></li></ul></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2019-2024
<a href=https://daemon365.dev/>daemon365</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js integrity="sha512-q583ppKrCRc7N5O0n2nzUiJ+suUv7Et1JGels4bXOaMFQcamPk9HjdUknZuuFjBNs7tsMuadge5k9RzdmO+1GQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js integrity="sha512-LCKPTo0gtJ74zCNMbWw04ltmujpzSR4oW+fgN+Y1YclhM5ZrHCZQAJE4quEodcI/G122sRhSGU2BsSRUZ2Gu3w==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js integrity="sha512-GP4x8UWxWyh4BMbyJGOGneiTbkrWEF5izsVJByzVLodP8CuJH/n936+yQDMJJrOPUHLgyPbLiGw2rXmdvGdXHA==" crossorigin=anonymous></script><script defer src=/assets/js/fuji.min.645f1123be695831f419ab54c1bcba327325895c740014006e57070d4f3e5d6b553e929c4b46f40ea707249e9c7f7c2a446d32a39ce7319f80a34525586a8e0f.js integrity="sha512-ZF8RI75pWDH0GatUwby6MnMliVx0ABQAblcHDU8+XWtVPpKcS0b0DqcHJJ6cf3wqRG0yo5znMZ+Ao0UlWGqODw=="></script></body></html>