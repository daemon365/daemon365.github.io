<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=HandheldFriendly content="True"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=generator content="Hugo 0.128.1"><link rel="shortcut icon" href=/imgs/icons/favicon.ico><title>kubernetes container device interface (CDI) - Daemon</title>
<meta name=author content="daemon365"><meta name=description content="Don't let yourself stop."><meta name=keywords content="cdi,kubernetes"><meta property="og:title" content="kubernetes container device interface (CDI)"><meta name=twitter:title content="kubernetes container device interface (CDI)"><meta property="og:type" content="article"><meta property="og:url" content="https://daemon365.dev/2023/11/19/kubernetes-container-device-interface-cdi/"><meta property="og:description" content="CDI 是什么？ Container Device Interface (CDI) 是一个提议的标准，它定义了如何在容器运行时环境中向容器提供设备。这个提议的目的是使得设备供应商能够更容易地将其设备集成到 Kubernetes 集群中，而不必修改 Kubernetes 核心代码。 CDI 插件通常负责： 配置设备以供容"><meta name=twitter:description content="CDI 是什么？ Container Device Interface (CDI) 是一个提议的标准，它定义了如何在容器运行时环境中向容器提供设备。这个提议的目的是使得设备供应商能够更容易地将其设备集成到 Kubernetes 集群中，而不必修改 Kubernetes 核心代码。 CDI 插件通常负责： 配置设备以供容"><meta property="og:image" content="https://daemon365.dev/imgs/icons/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://daemon365.dev/imgs/icons/favicon.ico"><meta property="article:published_time" content="2023-11-19T00:00:00+08:00"><meta property="article:modified_time" content="2023-11-19T00:00:00+08:00"><style>@media(prefers-color-scheme:dark){body[data-theme=auto] img{filter:brightness(60%)}}body[data-theme=dark] img{filter:brightness(60%)}</style><link rel=stylesheet href=https://daemon365.dev/assets/css/fuji.min.4e0456c767a797dadceacfba968921e887d900af9fd8d0953bebc1524ea1dec6c6a4a5ec0c0b77280884a642028ce374f31206dd96c6d7d143d5ee3c372f2c31.css integrity="sha512-TgRWx2enl9rc6s+6lokh6IfZAK+f2NCVO+vBUk6h3sbGpKXsDAt3KAiEpkICjON08xIG3ZbG19FD1e48Ny8sMQ=="></head><body data-theme=light data-theme-auto=false><script data-cfasync=false>var fujiThemeData=localStorage.getItem("fuji_data-theme");fujiThemeData?fujiThemeData!=="auto"&&document.body.setAttribute("data-theme",fujiThemeData==="dark"?"dark":"light"):localStorage.setItem("fuji_data-theme","auto")</script><header><div class="container-lg clearfix"><div class="col-12 header"><a class=title-main href=https://daemon365.dev/>Daemon</a>
<span class=title-sub>Don't let yourself stop.</span></div></div></header><main><div class="container-lg clearfix"><div class="col-12 col-md-9 float-left content"><article><h2 class="post-item post-title"><a href=https://daemon365.dev/2023/11/19/kubernetes-container-device-interface-cdi/>kubernetes container device interface (CDI)</a></h2><div class="post-item post-meta"><span><i class="iconfont icon-today-sharp"></i>&nbsp;2023-11-19</span>
<span><i class="iconfont icon-file-tray-sharp"></i>&nbsp;2658 words</span>
<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href=/tags/cdi>cdi</a>&nbsp;<a href=/tags/kubernetes>kubernetes</a>&nbsp;</span></div><div class="post-content markdown-body"><h2 id=cdi-是什么>CDI 是什么？</h2><p>Container Device Interface (CDI) 是一个提议的标准，它定义了如何在容器运行时环境中向容器提供设备。这个提议的目的是使得设备供应商能够更容易地将其设备集成到 Kubernetes 集群中，而不必修改 Kubernetes 核心代码。</p><p>CDI 插件通常负责：</p><ol><li>配置设备以供容器使用（例如，分配设备文件或设置必要的环境变量）。</li><li>在容器启动时将设备资源注入到容器中。</li></ol><p><strong>官网</strong></p><ul><li><a href=https://github.com/cncf-tags/container-device-interface target=_blank>https://github.com/cncf-tags/container-device-interface</a></li></ul><h2 id=为什么需要cdi>为什么需要CDI？</h2><p>如果我们想在容器内使用 nvidia 的 gpu，在没有 CDI 之前，我们需要修改 containerd 的 low-level container runtime(runc) 到 nvidia runtime。这么做的原因就是使用 gpu 不单单要绑定 gpu device 文件到容器内，还需要绑定一些驱动文件和可执行命令（比如 nvidia-smi）等到容器内，还有就执行一些 hooks。 nvidia runtime 的作用就是绑定一些文件和执行一些 hooks 然后调用 runc。</p><p>现在我们可以使用 CDI 做这些事情，除了无需修改 runtime 外，还有抽象和插件化等优点。</p><h2 id=版本及准备工作>版本及准备工作</h2><ul><li>kubelet version >= 1.28.0</li><li>containerd version >= 1.7.0</li></ul><p>而且这在 k8s 1.28 (1.29版本是 beta 了 默认就打开了) 版本中是一个 alpha 版本的功能，所以我们需要在 kubelet 的启动参数中加入开启特性门：<code>--feature-gates=DevicePluginCDIDevices =true</code>。</p><pre><code class=language-bash>sudo vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS --feature-gates=DevicePluginCDIDevices=true
</code></pre><p>containerd 也需要开启 CDI cdi_spec_dirs 为 cdi 配置文件的目录，enable_cdi 为开启 CDI 功能。</p><pre><code class=language-bash>sudo vim /etc/containerd/config.toml

cdi_spec_dirs = [&quot;/etc/cdi&quot;, &quot;/var/run/cdi&quot;]
enable_cdi = true
</code></pre><p>重启 containerd 和 kubelet</p><pre><code class=language-bash>sudo systemctl restart kubelet.service containerd.service
</code></pre><h2 id=mock>mock</h2><p>因为我的集群里没有 gpu , 所以我就随便 mock 几个文件作为 device 了。</p><pre><code class=language-bash>sudo mkdir /dev/mock
cd /dev/mock

sudo mknod /dev/mock/device_0 c 89 1
sudo mknod /dev/mock/device_1 c 89 1
sudo mknod /dev/mock/device_2 c 89 1
sudo mknod /dev/mock/device_3 c 89 1
sudo mknod /dev/mock/device_4 c 89 1
sudo mknod /dev/mock/device_5 c 89 1
sudo mknod /dev/mock/device_6 c 89 1
sudo mknod /dev/mock/device_7 c 89 1
</code></pre><pre><code class=language-bash>sudo vim /mock/bin/list_device.sh
#!/bin/bash

# 定义目录数组
directories=(/dev /dev/mock)

# 遍历目录数组
for dir in &quot;${directories[@]}&quot;; do
  # 检查目录是否存在
  if [ -d &quot;$dir&quot; ]; then
    # 目录存在，打印目录下的所有文件
    ls  &quot;$dir&quot;
  fi
done

sudo chmod a+x /mock/bin/list_device.sh
</code></pre><pre><code class=language-bash>sudo mkdir /mock/so
cd /mock/so
sudo touch device_0.so device_1.so device_2.so device_3.so device_5.so device_6.so device_7.so device_4.so
</code></pre><h2 id=开启-kubelet-的-device-plugin>开启 kubelet 的 device plugin</h2><p>下面是简单写的一个 device plugin，及其 dockerfile 还有部署到 k8s 的 yaml 文件。</p><pre><code class=language-go>package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;time&quot;

	&quot;github.com/kubevirt/device-plugin-manager/pkg/dpm&quot;
	pluginapi &quot;k8s.io/kubelet/pkg/apis/deviceplugin/v1beta1&quot;
)

type PluginLister struct {
	ResUpdateChan chan dpm.PluginNameList
}

var ResourceNamespace = &quot;mock.com&quot;
var PluginName = &quot;gpu&quot;

func (p *PluginLister) GetResourceNamespace() string {
	return ResourceNamespace
}

func (p *PluginLister) Discover(pluginListCh chan dpm.PluginNameList) {
	pluginListCh &lt;- dpm.PluginNameList{PluginName}
}

func (p *PluginLister) NewPlugin(name string) dpm.PluginInterface {
	return &amp;Plugin{}
}

type Plugin struct {
}

func (p *Plugin) GetDevicePluginOptions(ctx context.Context, e *pluginapi.Empty) (*pluginapi.DevicePluginOptions, error) {
	options := &amp;pluginapi.DevicePluginOptions{
		PreStartRequired: true,
	}
	return options, nil
}

func (p *Plugin) PreStartContainer(ctx context.Context, r *pluginapi.PreStartContainerRequest) (*pluginapi.PreStartContainerResponse, error) {
	return &amp;pluginapi.PreStartContainerResponse{}, nil
}

func (p *Plugin) GetPreferredAllocation(ctx context.Context, r *pluginapi.PreferredAllocationRequest) (*pluginapi.PreferredAllocationResponse, error) {
	return &amp;pluginapi.PreferredAllocationResponse{}, nil
}

func (p *Plugin) ListAndWatch(e *pluginapi.Empty, r pluginapi.DevicePlugin_ListAndWatchServer) error {
	devices := []*pluginapi.Device{}
	for i := 0; i &lt; 8; i++ {
		devices = append(devices, &amp;pluginapi.Device{
			// 和 device 名称保持一致
			ID:     fmt.Sprintf(&quot;device_%d&quot;, i),
			Health: pluginapi.Healthy,
		})
	}
	for {
		fmt.Println(&quot;register devices&quot;)
		// 每分钟注册一次
		r.Send(&amp;pluginapi.ListAndWatchResponse{
			Devices: devices,
		})
		time.Sleep(time.Second * 60)
	}
}

func (p *Plugin) Allocate(ctx context.Context, r *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) {
	// 使用cdi插件
	responses := &amp;pluginapi.AllocateResponse{}
	for _, req := range r.ContainerRequests {
		cdidevices := []*pluginapi.CDIDevice{}
		for _, id := range req.DevicesIDs {
			cdidevices = append(cdidevices, &amp;pluginapi.CDIDevice{
				Name: fmt.Sprintf(&quot;%s/%s=%s&quot;, ResourceNamespace, PluginName, id),
			})
		}
		responses.ContainerResponses = append(responses.ContainerResponses, &amp;pluginapi.ContainerAllocateResponse{
			CDIDevices: cdidevices,
		})
	}
	return responses, nil
}

func main() {
	m := dpm.NewManager(&amp;PluginLister{})
	m.Run()
}
</code></pre><pre><code class=language-Dockerfile>FROM golang:1.21.3 as builder
  
COPY . /src
WORKDIR /src
RUN go env -w GO111MODULE=on &amp;&amp; go env -w GOPROXY=https://goproxy.io,direct
RUN go build
  
FROM debian:bookworm-slim
  
RUN sed -i 's/deb.debian.org/mirrors.ustc.edu.cn/g' /etc/apt/sources.list.d/debian.sources
  
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
      ca-certificates   \
      netbase \
      pciutils \
      curl \
      &amp;&amp; rm -rf /var/lib/apt/lists/ \
      &amp;&amp; apt-get autoremove -y &amp;&amp; apt-get autoclean -y
  
RUN update-pciids
  
COPY --from=builder /src /app
  
WORKDIR /app
</code></pre><pre><code class=language-yaml>apiVersion: v1
kind: Namespace
metadata:
  name: mock-plugin
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: mock-plugin-daemonset
  namespace: mock-plugin
spec:
  selector:
    matchLabels:
      name: mock-plugin
  template:
    metadata:
      labels:
        name: mock-plugin
        app.kubernetes.io/component: mock-plugin
        app.kubernetes.io/name: mock-plugin
    spec:
      containers:
      - image: zhaohaiyu/mock:v1
        name: mock-plugin
        command: ['/app/mock']
        imagePullPolicy: Always
        securityContext:
          privileged: true
        tty: true
        volumeMounts:
        - name: kubelet
          mountPath: /var/lib/kubelet
      volumes:
      - name: kubelet
        hostPath:
          path: /var/lib/kubelet
</code></pre><p>执行完毕使用 kubectl 查看</p><pre><code class=language-bash>❯ kubectl -n mock-plugin get pod
NAME                          READY   STATUS    RESTARTS   AGE
mock-plugin-daemonset-8w2r8   1/1     Running   0          3m27s
</code></pre><p>查看 node 是否已经注册了 device plugin</p><pre><code class=language-bash>kubectl describe node node1

Capacity:
  cpu:                8
  ephemeral-storage:  102626232Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             24570324Ki
  mock.com/gpu:       8
  pods:               110
Allocatable:
  cpu:                8
  ephemeral-storage:  94580335255
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             24467924Ki
  mock.com/gpu:       8
  pods:               110
</code></pre><p>可以看到已经注册了 8 个 gpu 设备 名字叫 mock.com/gpu 也就是我们代码中定义的。</p><h2 id=cdi配置文件>CDI配置文件</h2><p>CDI Spec: <a href=https://github.com/cncf-tags/container-device-interface/blob/main/SPEC.md target=_blank>https://github.com/cncf-tags/container-device-interface/blob/main/SPEC.md</a></p><p>我们也生成了一个 CDI 的配置文件，这个配置文件会被 containerd 读取，然后根据配置文件中的信息去调用 device plugin。</p><pre><code class=language-yaml># vim /etc/cdi/mock.yaml
cdiVersion: 0.5.0
kind: mock.com/gpu
devices:

- name: device_0
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_0&quot;
      path: &quot;/dev/mock/device_0&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_0.so&quot;
      containerPath: &quot;/mock/so/device_0.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_1
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_1&quot;
      path: &quot;/dev/mock/device_1&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_1.so&quot;
      containerPath: &quot;/mock/so/device_1.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_2
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_2&quot;
      path: &quot;/dev/mock/device_2&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_2.so&quot;
      containerPath: &quot;/mock/so/device_2.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_3
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_3&quot;
      path: &quot;/dev/mock/device_3&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_3.so&quot;
      containerPath: &quot;/mock/so/device_3.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_4
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_4&quot;
      path: &quot;/dev/mock/device_4&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_4.so&quot;
      containerPath: &quot;/mock/so/device_4.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_5
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_5&quot;
      path: &quot;/dev/mock/device_5&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_5.so&quot;
      containerPath: &quot;/mock/so/device_5.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_6
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_6&quot;
      path: &quot;/dev/mock/device_6&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_6.so&quot;
      containerPath: &quot;/mock/so/device_6.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind

- name: device_7
  containerEdits:
    deviceNodes:
    - hostPath: &quot;/dev/mock/device_7&quot;
      path: &quot;/dev/mock/device_7&quot;
      type: c
      permissions: rw
    mounts:
    - hostPath: &quot;/mock/so/device_7.so&quot;
      containerPath: &quot;/mock/so/device_7.so&quot;
      options:
      - ro
      - nosuid
      - nodev
      - bind


containerEdits:
  mounts:
  - hostPath: &quot;/mock/bin/list_device.sh&quot;
    containerPath: &quot;/usr/local/bin/list_device.sh&quot;
    options:
    - ro
    - nosuid
    - nodev
    - bind
</code></pre><p>这里我只是简单示例，还有 hooks 和 env 等用法查看官方文档。</p><h2 id=部署-pod>部署 pod</h2><p>我部署一个 pod 使用 mock gpu 这个资源 4个。</p><pre><code class=language-YAML>apiVersion: v1
kind: Pod
metadata:
  name: ubuntu1
spec:
  containers:
  - name: ubuntu-container
    image: ubuntu:latest
    command: [&quot;sleep&quot;]
    args: [&quot;3600&quot;]
    resources:
      requests:
        memory: &quot;64Mi&quot;
        cpu: &quot;250m&quot;
        mock.com/gpu: &quot;4&quot;
      limits:
        memory: &quot;128Mi&quot;
        cpu: &quot;500m&quot;
        mock.com/gpu: &quot;4&quot;
</code></pre><pre><code class=language-bash>ubuntu1   1/1     Running   0          49s
</code></pre><p>现在我们 使用 <code>kubectl exec -it ubuntu1 bash</code> 进入容器看一看。</p><pre><code class=language-bash>ls /dev/mock/
device_0  device_1  device_6  device_7

ls /mock/so/
device_0.so  device_1.so  device_6.so  device_7.so

list_device.sh
so
device_0  device_1  device_6  device_7
</code></pre><p>可以看到我们 cdi 配置文件配置的 device 和 so 文件和还有我们的 list_device.sh 都已经挂载到容器内了。</p><p>我现在再启动一个 pod 使用 mock gpu 这个资源 3 个。</p><pre><code class=language-YAML>apiVersion: v1
kind: Pod
metadata:
  name: ubuntu2
spec:
  containers:
  - name: ubuntu-container
    image: ubuntu:latest
    command: [&quot;sleep&quot;]
    args: [&quot;3600&quot;]
    resources:
      requests:
        memory: &quot;64Mi&quot;
        cpu: &quot;250m&quot;
        mock.com/gpu: &quot;3&quot;
      limits:
        memory: &quot;128Mi&quot;
        cpu: &quot;500m&quot;
        mock.com/gpu: &quot;3&quot;
</code></pre><pre><code class=language-bash>ls /dev/mock/
device_2  device_3  device_5
</code></pre><p>查看node使用了多少资源</p><pre><code>Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                1550m (19%)  1 (12%)
  memory             668Mi (2%)   596Mi (2%)
  ephemeral-storage  0 (0%)       0 (0%)
  hugepages-1Gi      0 (0%)       0 (0%)
  hugepages-2Mi      0 (0%)       0 (0%)
  mock.com/gpu       7            7
</code></pre><p>可以看到我们使用了 7 个 mock.com/gpu 资源，还剩下 1 个。</p><h2 id=nvdia-gpu>nvdia gpu</h2><p>我找了一台带有 nvidia gpu 的机器，然后安装了 nvidia-container-toolkit-base。</p><p>使用 <code>nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml</code> 生产 cdi 配置文件。</p><pre><code class=language-yaml>---
cdiVersion: 0.5.0
containerEdits:
  deviceNodes:
  - path: /dev/nvidia-modeset
  - path: /dev/nvidia-uvm
  - path: /dev/nvidia-uvm-tools
  - path: /dev/nvidiactl
  hooks:
  - args:
    - nvidia-ctk
    - hook
    - create-symlinks
    - --link
    - libglxserver_nvidia.so.525.147.05::/usr/lib/x86_64-linux-gnu/nvidia/xorg/libglxserver_nvidia.so
    hookName: createContainer
    path: /usr/bin/nvidia-ctk
  - args:
    - nvidia-ctk
    - hook
    - update-ldcache
    - --folder
    - /usr/lib/x86_64-linux-gnu
    hookName: createContainer
    path: /usr/bin/nvidia-ctk
  mounts:
  - containerPath: /run/nvidia-persistenced/socket
    hostPath: /run/nvidia-persistenced/socket
    options:
    - ro
    - nosuid
    - nodev
    - bind
    - noexec
  - containerPath: /usr/bin/nvidia-cuda-mps-control
    hostPath: /usr/bin/nvidia-cuda-mps-control
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/bin/nvidia-cuda-mps-server
    hostPath: /usr/bin/nvidia-cuda-mps-server
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/bin/nvidia-debugdump
    hostPath: /usr/bin/nvidia-debugdump
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/bin/nvidia-persistenced
    hostPath: /usr/bin/nvidia-persistenced
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/bin/nvidia-smi
    hostPath: /usr/bin/nvidia-smi
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libEGL_nvidia.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libEGL_nvidia.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libGLESv1_CM_nvidia.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libGLESv1_CM_nvidia.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libGLESv2_nvidia.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libGLESv2_nvidia.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libGLX_nvidia.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libGLX_nvidia.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libcuda.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libcuda.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libcudadebugger.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libcudadebugger.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvcuvid.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvcuvid.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-egl-gbm.so.1.1.0
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-egl-gbm.so.1.1.0
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-eglcore.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-eglcore.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-fbc.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-fbc.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-glcore.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-glcore.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-glsi.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-glsi.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-glvkspirv.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-glvkspirv.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-ngx.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-ngx.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvidia-tls.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvidia-tls.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/libnvoptix.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/libnvoptix.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /lib/firmware/nvidia/525.147.05/gsp_ad10x.bin
    hostPath: /lib/firmware/nvidia/525.147.05/gsp_ad10x.bin
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /lib/firmware/nvidia/525.147.05/gsp_tu10x.bin
    hostPath: /lib/firmware/nvidia/525.147.05/gsp_tu10x.bin
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/share/X11/xorg.conf.d/10-nvidia.conf
    hostPath: /usr/share/X11/xorg.conf.d/10-nvidia.conf
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/share/egl/egl_external_platform.d/15_nvidia_gbm.json
    hostPath: /usr/share/egl/egl_external_platform.d/15_nvidia_gbm.json
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/share/glvnd/egl_vendor.d/10_nvidia.json
    hostPath: /usr/share/glvnd/egl_vendor.d/10_nvidia.json
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/share/vulkan/icd.d/nvidia_icd.json
    hostPath: /usr/share/vulkan/icd.d/nvidia_icd.json
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/nvidia/xorg/libglxserver_nvidia.so.525.147.05
    hostPath: /usr/lib/x86_64-linux-gnu/nvidia/xorg/libglxserver_nvidia.so.525.147.05
    options:
    - ro
    - nosuid
    - nodev
    - bind
  - containerPath: /usr/lib/x86_64-linux-gnu/nvidia/xorg/nvidia_drv.so
    hostPath: /usr/lib/x86_64-linux-gnu/nvidia/xorg/nvidia_drv.so
    options:
    - ro
    - nosuid
    - nodev
    - bind
devices:
- containerEdits:
    deviceNodes:
    - path: /dev/nvidia0
    - path: /dev/dri/card0
    - path: /dev/dri/renderD128
    hooks:
    - args:
      - nvidia-ctk
      - hook
      - create-symlinks
      - --link
      - ../card0::/dev/dri/by-path/pci-0000:01:00.0-card
      - --link
      - ../renderD128::/dev/dri/by-path/pci-0000:01:00.0-render
      hookName: createContainer
      path: /usr/bin/nvidia-ctk
    - args:
      - nvidia-ctk
      - hook
      - chmod
      - --mode
      - &quot;755&quot;
      - --path
      - /dev/dri
      hookName: createContainer
      path: /usr/bin/nvidia-ctk
  name: &quot;0&quot;
- containerEdits:
    deviceNodes:
    - path: /dev/nvidia0
    - path: /dev/dri/card0
    - path: /dev/dri/renderD128
    hooks:
    - args:
      - nvidia-ctk
      - hook
      - create-symlinks
      - --link
      - ../card0::/dev/dri/by-path/pci-0000:01:00.0-card
      - --link
      - ../renderD128::/dev/dri/by-path/pci-0000:01:00.0-render
      hookName: createContainer
      path: /usr/bin/nvidia-ctk
    - args:
      - nvidia-ctk
      - hook
      - chmod
      - --mode
      - &quot;755&quot;
      - --path
      - /dev/dri
      hookName: createContainer
      path: /usr/bin/nvidia-ctk
  name: all
kind: nvidia.com/gpu
</code></pre><p>可以看到 nvidia 的 cdi 配置文件比 mock 的要复杂很多，因为 nvidia 的 gpu 需要绑定很多文件到容器内，还有 hooks 等。这些工作之前都是在 runtime 中做的，现在都可以通过 cdi 插件来做了。</p></div></article><div class="license markdown-body"><blockquote><p>Unless otherwise noted, the content of this site is licensed under <a rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0</a>.</p></blockquote></div></div><aside class="col-12 col-md-3 float-left sidebar"><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archives</a></li><li><a href=/index.xml>RSS</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/daemon365 target=_blank><span>My GitHub</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bbr/>BBR</a>
</span><span><a href=/tags/boltdb/>Boltdb</a>
</span><span><a href=/tags/breaker/>Breaker</a>
</span><span><a href=/tags/cdi/>Cdi</a>
</span><span><a href=/tags/cgroup/>Cgroup</a>
</span><span><a href=/tags/client-go/>Client-Go</a>
</span><span><a href=/tags/cni/>Cni</a>
</span><span><a href=/tags/containerd/>Containerd</a>
</span><span><a href=/tags/containerd-shim/>Containerd-Shim</a>
</span><span><a href=/tags/cri/>Cri</a>
</span><span><a href=/tags/csi/>Csi</a>
</span><span><a href=/tags/docker/>Docker</a>
</span><span><a href=/tags/etcd/>Etcd</a>
</span><span><a href=/tags/gin/>Gin</a>
</span><span><a href=/tags/go/>Go</a>
</span><span><a href=/tags/golang/>Golang</a>
</span><span><a href=/tags/grpc/>Grpc</a>
</span><span><a href=/tags/iptables/>Iptables</a>
</span><span><a href=/tags/ipvs/>Ipvs</a>
</span><span><a href=/tags/istio/>Istio</a>
</span><span><a href=/tags/kratos/>Kratos</a>
</span><span><a href=/tags/kube-proxy/>Kube-Proxy</a>
</span><span><a href=/tags/kubelet/>Kubelet</a>
</span><span><a href=/tags/kubernetes/>Kubernetes</a>
</span><span><a href=/tags/linux/>Linux</a>
</span><span><a href=/tags/lua/>Lua</a>
</span><span><a href=/tags/makefile/>Makefile</a>
</span><span><a href=/tags/mysql/>Mysql</a>
</span><span><a href=/tags/namespace/>Namespace</a>
</span><span><a href=/tags/network/>Network</a>
</span><span><a href=/tags/nginx/>Nginx</a>
</span><span><a href=/tags/opentelemetry/>Opentelemetry</a>
</span><span><a href=/tags/prometheus/>Prometheus</a>
</span><span><a href=/tags/protobuf/>Protobuf</a>
</span><span><a href=/tags/rabbitmq/>RabbitMQ</a>
</span><span><a href=/tags/redis/>Redis</a>
</span><span><a href=/tags/runc/>Runc</a>
</span><span><a href=/tags/service-mesh/>Service Mesh</a>
</span><span><a href=/tags/sidecar/>Sidecar</a>
</span><span><a href=/tags/sqlx/>Sqlx</a>
</span><span><a href=/tags/thrift/>Thrift</a>
</span><span><a href=/tags/unionfs/>UnionFS</a>
</span><span><a href=/tags/viper/>Viper</a>
</span><span><a href=/tags/vscode/>Vscode</a>
</span><span><a href=/tags/wire/>Wire</a>
</span><span><a href=/tags/zap/>Zap</a>
</span><span><a href=/tags/%E4%BA%8B%E5%8A%A1/>事务</a>
</span><span><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a>
</span><span><a href=/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/>源码分析</a>
</span><span><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>设计模式</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#cdi-是什么>CDI 是什么？</a></li><li><a href=#为什么需要cdi>为什么需要CDI？</a></li><li><a href=#版本及准备工作>版本及准备工作</a></li><li><a href=#mock>mock</a></li><li><a href=#开启-kubelet-的-device-plugin>开启 kubelet 的 device plugin</a></li><li><a href=#cdi配置文件>CDI配置文件</a></li><li><a href=#部署-pod>部署 pod</a></li><li><a href=#nvdia-gpu>nvdia gpu</a></li></ul></nav></div></aside></div><div class=btn><div class=btn-menu id=btn-menu><i class="iconfont icon-grid-sharp"></i></div><div class=btn-toggle-mode><i class="iconfont icon-contrast-sharp"></i></div><div class=btn-scroll-top><i class="iconfont icon-chevron-up-circle-sharp"></i></div></div><aside class=sidebar-mobile style=display:none><div class=sidebar-wrapper><div class="sidebar-item sidebar-pages"><h3>Pages</h3><ul><li><a href=/>Home</a></li><li><a href=/archives/>Archives</a></li><li><a href=/index.xml>RSS</a></li><li><a href=/about/>About</a></li><li><a href=/search/>Search</a></li></ul></div><div class="sidebar-item sidebar-links"><h3>Links</h3><ul><li><a href=https://github.com/daemon365 target=_blank><span>My GitHub</span></a></li></ul></div><div class="sidebar-item sidebar-tags"><h3>Tags</h3><div><span><a href=/tags/bbr/>BBR</a>
</span><span><a href=/tags/boltdb/>Boltdb</a>
</span><span><a href=/tags/breaker/>Breaker</a>
</span><span><a href=/tags/cdi/>Cdi</a>
</span><span><a href=/tags/cgroup/>Cgroup</a>
</span><span><a href=/tags/client-go/>Client-Go</a>
</span><span><a href=/tags/cni/>Cni</a>
</span><span><a href=/tags/containerd/>Containerd</a>
</span><span><a href=/tags/containerd-shim/>Containerd-Shim</a>
</span><span><a href=/tags/cri/>Cri</a>
</span><span><a href=/tags/csi/>Csi</a>
</span><span><a href=/tags/docker/>Docker</a>
</span><span><a href=/tags/etcd/>Etcd</a>
</span><span><a href=/tags/gin/>Gin</a>
</span><span><a href=/tags/go/>Go</a>
</span><span><a href=/tags/golang/>Golang</a>
</span><span><a href=/tags/grpc/>Grpc</a>
</span><span><a href=/tags/iptables/>Iptables</a>
</span><span><a href=/tags/ipvs/>Ipvs</a>
</span><span><a href=/tags/istio/>Istio</a>
</span><span><a href=/tags/kratos/>Kratos</a>
</span><span><a href=/tags/kube-proxy/>Kube-Proxy</a>
</span><span><a href=/tags/kubelet/>Kubelet</a>
</span><span><a href=/tags/kubernetes/>Kubernetes</a>
</span><span><a href=/tags/linux/>Linux</a>
</span><span><a href=/tags/lua/>Lua</a>
</span><span><a href=/tags/makefile/>Makefile</a>
</span><span><a href=/tags/mysql/>Mysql</a>
</span><span><a href=/tags/namespace/>Namespace</a>
</span><span><a href=/tags/network/>Network</a>
</span><span><a href=/tags/nginx/>Nginx</a>
</span><span><a href=/tags/opentelemetry/>Opentelemetry</a>
</span><span><a href=/tags/prometheus/>Prometheus</a>
</span><span><a href=/tags/protobuf/>Protobuf</a>
</span><span><a href=/tags/rabbitmq/>RabbitMQ</a>
</span><span><a href=/tags/redis/>Redis</a>
</span><span><a href=/tags/runc/>Runc</a>
</span><span><a href=/tags/service-mesh/>Service Mesh</a>
</span><span><a href=/tags/sidecar/>Sidecar</a>
</span><span><a href=/tags/sqlx/>Sqlx</a>
</span><span><a href=/tags/thrift/>Thrift</a>
</span><span><a href=/tags/unionfs/>UnionFS</a>
</span><span><a href=/tags/viper/>Viper</a>
</span><span><a href=/tags/vscode/>Vscode</a>
</span><span><a href=/tags/wire/>Wire</a>
</span><span><a href=/tags/zap/>Zap</a>
</span><span><a href=/tags/%E4%BA%8B%E5%8A%A1/>事务</a>
</span><span><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a>
</span><span><a href=/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/>源码分析</a>
</span><span><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>设计模式</a></span></div></div><div class="sidebar-item sidebar-toc"><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#cdi-是什么>CDI 是什么？</a></li><li><a href=#为什么需要cdi>为什么需要CDI？</a></li><li><a href=#版本及准备工作>版本及准备工作</a></li><li><a href=#mock>mock</a></li><li><a href=#开启-kubelet-的-device-plugin>开启 kubelet 的 device plugin</a></li><li><a href=#cdi配置文件>CDI配置文件</a></li><li><a href=#部署-pod>部署 pod</a></li><li><a href=#nvdia-gpu>nvdia gpu</a></li></ul></nav></div></div></aside></main><footer><div class="container-lg clearfix"><div class="col-12 footer"><span>&copy; 2019-2024
<a href=https://daemon365.dev/>daemon365</a>
| Powered by <a href=https://github.com/dsrkafuu/hugo-theme-fuji/ target=_blank>Fuji-v2</a> & <a href=https://gohugo.io/ target=_blank>Hugo</a></span></div></div></footer><script defer src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js integrity="sha512-q583ppKrCRc7N5O0n2nzUiJ+suUv7Et1JGels4bXOaMFQcamPk9HjdUknZuuFjBNs7tsMuadge5k9RzdmO+1GQ==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/components/prism-core.min.js integrity="sha512-LCKPTo0gtJ74zCNMbWw04ltmujpzSR4oW+fgN+Y1YclhM5ZrHCZQAJE4quEodcI/G122sRhSGU2BsSRUZ2Gu3w==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/prismjs@1.27.0/plugins/autoloader/prism-autoloader.min.js integrity="sha512-GP4x8UWxWyh4BMbyJGOGneiTbkrWEF5izsVJByzVLodP8CuJH/n936+yQDMJJrOPUHLgyPbLiGw2rXmdvGdXHA==" crossorigin=anonymous></script><script defer src=/assets/js/fuji.min.645f1123be695831f419ab54c1bcba327325895c740014006e57070d4f3e5d6b553e929c4b46f40ea707249e9c7f7c2a446d32a39ce7319f80a34525586a8e0f.js integrity="sha512-ZF8RI75pWDH0GatUwby6MnMliVx0ABQAblcHDU8+XWtVPpKcS0b0DqcHJJ6cf3wqRG0yo5znMZ+Ao0UlWGqODw=="></script></body></html>